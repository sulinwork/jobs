# job-reptile
1、数据爬虫模块 负责数据的爬取
2、启动参数：
            1、爬取的关键字
            2、爬取的数据输出到具体的文件路径
            3、从多少页开始爬

 # jobs-etl
 1、负责对爬取的数据进行清洗
 2、清洗完成的数据写入HBase中
 3、输入参数：需要清洗的文件路径

# HBase的表创建
1、创建HBase表信息 预分区['0~','1~','2~']
create 'sulin:jobs','info','company',SPLITS => ['0~','1~','2~']

# Hive和Hbase关联  做数据分析
CREATE EXTERNAL TABLE t_jobs_hbase(
rowkey string,
jobType string,
jobName string,
jobArea string,
minSalary double,
maxSalary double,
workYearNeed string,
workEducation string,
needNum String,
putDate string,
jobRequirements string,
companyName string,
companyType string,
minCompanySize int,
maxCompanySize int,
companyindustry String
)
STORED BY 
'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
WITH SERDEPROPERTIES ("hbase.columns.mapping" = 
":key,info:jobType,info:jobName,info:jobArea,info:minSalary,info:maxSalary,info:workYearNeed,info:workEducation,
info:needNum,info:putDate,info:jobRequirements,company:companyName,company:companyType,company:minCompanySize,company:maxCompanySize,company:companyindustry") 
TBLPROPERTIES ("hbase.table.name" = "sulin:jobs");

# 分析HQL
# 根据每个岗位 分析岗位在不用城市的需求
select t.jobArea,t.jobType,t.jobCount from (
select temp.jobArea,temp.jobType,jobCount,rank() over(partition by temp.jobType order by temp.jobCount desc) as topid from (
select jobArea,jobType,count(*) as jobCount from  t_jobs_hbase where jobArea!='异地招聘' group by jobArea,jobType) temp ) t where t.topid<=10;

# 分析岗位对于不同学历上的需求人数
select jobType,workEducation,count(*) as jobCount from t_jobs_hbase group by jobType,workEducation;
# 分析岗位对于不同年限的人的需求人数
select jobType,workYearNeed,count(*) as jobCount from t_jobs_hbase group by jobType,workYearNeed;
# 行业领域
select jobType,split(companyindustry," ")[0] as industry,count(*) as jobCount from t_jobs_hbase group by jobType,split(companyindustry," ")[0]

# 分析的数据导出到HDFS
insert overwrite directory '/jobs/industry'
row format delimited fields terminated by '\t'

# 使用sqoop将数据从HDFS导入到MySql
sqoop export \
--connect jdbc:mysql://hdfs01:3306/jobs?useUnicode=true&characterEncoding=UTF-8 \
--username root \
--password 123456 \
--table t_city \
--num-mappers 1 \
--export-dir /jobs/city \
--input-fields-terminated-by "\t"

# job-web
web可视化页面


